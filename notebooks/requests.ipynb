{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This notebook was initially set up as looping to pull first 10,000 posts, following EDA notebook the loop was modified to include EDA code from there, and to pull many more times since a large amount were filtered. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "0b2395a4-bbbb-4d27-bb4a-f1ce62cf0785",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://api.pushshift.io/reddit/search/submission'"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "latest 100 posts from both subreddits stored as data frames, so that an initial dataframe to build upon, and 'before' timestamp can be established."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "8eaae975-3cca-4ba4-948c-9721788da1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_r = {\n",
    "    'subreddit': 'Conservative',\n",
    "    'size': 100\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "outputs": [],
   "source": [
    "params_d = {\n",
    "    'subreddit': 'democrats',\n",
    "    'size': 100\n",
    "\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "c001f0b7-5664-4f9c-b0df-84f5ae78d9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_r = requests.get(url, params_r)\n",
    "res_d = requests.get(url, params_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "83f349cc-f153-43ea-a23b-5fda49d4f76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "200"
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_r.status_code\n",
    "res_d.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "a3b33a10-c9ee-4411-9383-9cf12cce3d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_r = res_r.json()\n",
    "data_d = res_d.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "65e5519c-47ed-474c-b78a-a96e175817a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_r = data_r['data']\n",
    "posts_d = data_d['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "outputs": [],
   "source": [
    "before_r = data_r['data'][-1]['created_utc']\n",
    "before_d = data_d['data'][-1]['created_utc']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "outputs": [],
   "source": [
    "df_r = pd.DataFrame(posts_r)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "e920046d-36c2-4d0d-954c-3ca0b8df7484",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d = pd.DataFrame(posts_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "oldest post out of first pull of 100 checked against its index variable which will serve as starting point for loop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "3b142c7d-25b2-450a-a1b0-f05a0abffdbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "99    1642377533\nName: created_utc, dtype: int64"
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r['created_utc'].tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "outputs": [
    {
     "data": {
      "text/plain": "1642377533"
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before_r"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_d['created_utc'].tail(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "outputs": [
    {
     "data": {
      "text/plain": "1642104722"
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before_d"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "93d4b059-7517-42fb-a4e9-ac372d94721e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "now that an initial 'before' submission has been indexed, the loop can take care of the remaining post history, changing the before param each iteration seperately for the subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "2b4eccfb-eccb-46df-bfed-ccb4b628a1aa",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "before is set two different times, for each 100 pulls, of the outer definition 'append_subs' the oldest post date is recalculated and updated as the nested loop churns along\n",
    "\n",
    "source: gave it a go on my own, and came very close to getting it to work. After trying my best, I referenced classmates examples in slack for lines 21 and 27 specicially that made my initial loop work."
   ]
  },
  {
   "cell_type": "code",
   "id": "0c19b904-0dcc-4a6b-a31c-73e146430f38",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def pull_subs(subreddit, before_var, iterations):\n",
    "\n",
    "    posts = []\n",
    "    before = before_var\n",
    "\n",
    "\n",
    "    for i in range(1,iterations):\n",
    "        time.sleep(3)\n",
    "        params = {\n",
    "            'subreddit': subreddit,\n",
    "            'size': 100,\n",
    "            'before': before,\n",
    "            \"sort\": \"desc\",\n",
    "            \"sort_type\": \"created_utc\"\n",
    "        }\n",
    "\n",
    "        res = requests.get(url, params)\n",
    "\n",
    "        if res.status_code == 200:\n",
    "            before = res.json()['data'][-1]['created_utc']\n",
    "            posts += res.json()['data']\n",
    "\n",
    "        else:\n",
    "            print('invalid status code')\n",
    "\n",
    "\n",
    "    return pd.DataFrame(posts)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "a check to ensure that first loop works, but would mess up control flow in that local variables wouldn't be set properly for following nested loop."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "#pull_subs('democrats', before_d, 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loop #2: as first loop is generic to subreddit, this second loop nests the first, and computes an initial timestamp to serve as the 'before' input, so that the ongoing dataset for each subreddit contains no duplicates. 100 iterations of the first loop results in 10,000 posts."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "fead0a35-bad5-4541-b614-26e9dbe0c256",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def append_subs(data,subred):\n",
    "\n",
    "    before_new = data['created_utc'].iloc[-1]\n",
    "\n",
    "    df = pull_subs(subred, before_new, 100)\n",
    "\n",
    "    new_df = pd.concat([data,df])\n",
    "\n",
    "    return new_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "These two functions are called anytime more posts are to be added to dataset. Started with one iteration and then commented out, will call in later cell if more content is required. for now, eda will start in new eda notebook begining with csv files containing initial 10,000 records"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "#df_d = append_subs(df_d, 'democrats')\n",
    "#df_r = append_subs(df_r, 'Conservative')\n",
    "#df_d.to_csv('data/democrat10k.csv')\n",
    "#df_r.to_csv('data/conservative10k.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "df_d = append_subs(df_d, 'democrats')\n",
    "df_r = append_subs(df_r, 'Conservative')\n",
    "df_d.to_csv('./data/democrat20k.csv')\n",
    "df_r.to_csv('./data/conservative20k.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "df_d = append_subs(df_d, 'democrats')\n",
    "df_r = append_subs(df_r, 'Conservative')\n",
    "df_d.to_csv('./data/democrat30k.csv')\n",
    "df_r.to_csv('./data/conservative30k.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "df_d = append_subs(df_d, 'democrats')\n",
    "df_r = append_subs(df_r, 'Conservative')\n",
    "df_d.to_csv('./data/democrat40k.csv')\n",
    "df_r.to_csv('./data/conservative40k.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df_d = append_subs(df_d, 'democrats')\n",
    "df_r = append_subs(df_r, 'Conservative')\n",
    "df_d.to_csv('./data/democrat50k.csv')\n",
    "df_r.to_csv('./data/conservative50k.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "df_d = append_subs(df_d, 'democrats')\n",
    "df_r = append_subs(df_r, 'Conservative')\n",
    "df_d.to_csv('./data/democrat60k.csv')\n",
    "df_r.to_csv('./data/conservative60k.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "df_d = append_subs(df_d, 'democrats')\n",
    "df_r = append_subs(df_r, 'Conservative')\n",
    "df_d.to_csv('./data/democrat70k.csv')\n",
    "df_r.to_csv('./data/conservative70k.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "df_d = append_subs(df_d, 'democrats')\n",
    "df_r = append_subs(df_r, 'Conservative')\n",
    "df_d.to_csv('./data/democrat80k.csv')\n",
    "df_r.to_csv('./data/conservative80k.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "df_d = append_subs(df_d, 'democrats')\n",
    "df_r = append_subs(df_r, 'Conservative')\n",
    "df_d.to_csv('./data/democrat90k.csv')\n",
    "df_r.to_csv('./data/conservative90k.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "df_d = append_subs(df_d, 'democrats')\n",
    "df_r = append_subs(df_r, 'Conservative')\n",
    "df_d.to_csv('./data/democrat100k.csv')\n",
    "df_r.to_csv('./data/conservative100k.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}